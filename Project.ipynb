{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bibcode</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>verified_uat_ids</th>\n",
       "      <th>verified_uat_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020ApJ...891..100S</td>\n",
       "      <td>Dynamic Potential Sputtering of Lunar Analog M...</td>\n",
       "      <td>Pyroxenes ((Ca, Mg, Fe, Mn)&lt;SUB&gt;2&lt;/SUB&gt;Si&lt;SUB&gt;...</td>\n",
       "      <td>[1534, 499, 1692, 948, 1024, 2004]</td>\n",
       "      <td>[solar wind, exosphere, the moon, lunar compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024ApJ...966L...8B</td>\n",
       "      <td>Generation of Low-inclination, Neptune-crossin...</td>\n",
       "      <td>The solar system's distant reaches exhibit a w...</td>\n",
       "      <td>[1705, 1184, 2293]</td>\n",
       "      <td>[trans-neptunian objects, orbits, solar system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024PSJ.....5...45C</td>\n",
       "      <td>Leveraging the Gravity Field Spectrum for Icy ...</td>\n",
       "      <td>Understanding the interior structures of icy m...</td>\n",
       "      <td>[2189, 1248, 770, 1889, 627, 1255]</td>\n",
       "      <td>[europa, planetary interior, hydrosphere, mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022ApJ...932...52H</td>\n",
       "      <td>Inverse Multiview. I. Multicalibrator Inverse ...</td>\n",
       "      <td>Very Long Baseline Interferometry (VLBI) astro...</td>\n",
       "      <td>[1769, 1337, 1713, 1295]</td>\n",
       "      <td>[very long baseline interferometry, radio astr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024ApJS..271...25C</td>\n",
       "      <td>The First LHAASO Catalog of Gamma-Ray Sources</td>\n",
       "      <td>We present the first catalog of very-high-ener...</td>\n",
       "      <td>[628, 632, 205]</td>\n",
       "      <td>[gamma-ray astronomy, gamma-ray observatories,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bibcode                                              title  \\\n",
       "0  2020ApJ...891..100S  Dynamic Potential Sputtering of Lunar Analog M...   \n",
       "1  2024ApJ...966L...8B  Generation of Low-inclination, Neptune-crossin...   \n",
       "2  2024PSJ.....5...45C  Leveraging the Gravity Field Spectrum for Icy ...   \n",
       "3  2022ApJ...932...52H  Inverse Multiview. I. Multicalibrator Inverse ...   \n",
       "4  2024ApJS..271...25C      The First LHAASO Catalog of Gamma-Ray Sources   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Pyroxenes ((Ca, Mg, Fe, Mn)<SUB>2</SUB>Si<SUB>...   \n",
       "1  The solar system's distant reaches exhibit a w...   \n",
       "2  Understanding the interior structures of icy m...   \n",
       "3  Very Long Baseline Interferometry (VLBI) astro...   \n",
       "4  We present the first catalog of very-high-ener...   \n",
       "\n",
       "                     verified_uat_ids  \\\n",
       "0  [1534, 499, 1692, 948, 1024, 2004]   \n",
       "1                  [1705, 1184, 2293]   \n",
       "2  [2189, 1248, 770, 1889, 627, 1255]   \n",
       "3            [1769, 1337, 1713, 1295]   \n",
       "4                     [628, 632, 205]   \n",
       "\n",
       "                                 verified_uat_labels  \n",
       "0  [solar wind, exosphere, the moon, lunar compos...  \n",
       "1  [trans-neptunian objects, orbits, solar system...  \n",
       "2  [europa, planetary interior, hydrosphere, mark...  \n",
       "3  [very long baseline interferometry, radio astr...  \n",
       "4  [gamma-ray astronomy, gamma-ray observatories,...  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_parquet('train-00000-of-00001-b21313e511aa601a.parquet')\n",
    "\n",
    "# Drop rows with any missing values\n",
    "data = data.dropna(ignore_index=True)\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Loading the data, we're going to prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va créer un dictionnaire avec les valeurs des ids vérifiés, associé à chaque label vérifié et créer une liste Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_and_labels = data[['verified_uat_ids','verified_uat_labels']]\n",
    "\n",
    "maxi = 0\n",
    "for i in data['verified_uat_ids']: \n",
    "    for j in i:\n",
    "        if j>maxi:\n",
    "            maxi = j\n",
    "\n",
    "y_liste = np.zeros((len(data),maxi+1))\n",
    "\n",
    "dict_ids_labels = {}\n",
    "\n",
    "for i in range(len(ids_and_labels['verified_uat_ids'])):\n",
    "    for j in range(len(ids_and_labels['verified_uat_ids'][i])):\n",
    "        y_liste[i][ids_and_labels['verified_uat_ids'][i][j]] = 1\n",
    "        dict_ids_labels[ids_and_labels['verified_uat_ids'][i][j]] = ids_and_labels['verified_uat_labels'][i][j]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Y with columns equals to the value of the labels, with 1 if the label appears in the data for each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Dynamic Potential Sputtering Lunar Analog Mate...\n",
       "1        Generation Low-inclination, Neptune-crossing T...\n",
       "2        Leveraging Gravity Field Spectrum Satellite In...\n",
       "3        Inverse Multiview. Multicalibrator Inverse Pha...\n",
       "4        First LHAASO Catalog Gamma-Ray SourcesWe prese...\n",
       "                               ...                        \n",
       "18628    X-Ray Spectroscopy Microcalorimeter Era. III. ...\n",
       "18629    Fast Iterative Techniques Polarized Radiative ...\n",
       "18630    Characterization Supernovae Based Spectral-Tem...\n",
       "18631    Evidence Coronal Temperature Variation Seyfert...\n",
       "18632    LoVoCCS. Survey Introduction, Data Processing ...\n",
       "Length: 18633, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data['title'] + data['abstract']\n",
    "X = X.apply(lambda x: ' '.join([word for word in x.split() if len(word) > 3]))\n",
    "Y = pd.DataFrame(y_liste)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to separate our data into train and test datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to tokenize the text, by the frequence of each word, so our model can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 1565026 stored elements and shape (14906, 47040)>\n",
      "  Coords\tValues\n",
      "  (0, 16789)\t0.0641474073605073\n",
      "  (0, 41797)\t0.12546661965716513\n",
      "  (0, 36953)\t0.07746819223684998\n",
      "  (0, 12109)\t0.2483468815673644\n",
      "  (0, 32222)\t0.22011280998651084\n",
      "  (0, 33491)\t0.12230722545290991\n",
      "  (0, 20225)\t0.09160147048607467\n",
      "  (0, 15428)\t0.08271653084556393\n",
      "  (0, 36958)\t0.08271653084556393\n",
      "  (0, 39833)\t0.4022546635872688\n",
      "  (0, 22333)\t0.03138847210395375\n",
      "  (0, 10602)\t0.042048344428250325\n",
      "  (0, 14042)\t0.1376661955174148\n",
      "  (0, 34851)\t0.08200906881668871\n",
      "  (0, 40001)\t0.05044312017615956\n",
      "  (0, 20912)\t0.04534683926249641\n",
      "  (0, 14521)\t0.056315744913267796\n",
      "  (0, 36123)\t0.1343515298110958\n",
      "  (0, 14806)\t0.10460951093944178\n",
      "  (0, 45976)\t0.06540631028568886\n",
      "  (0, 7999)\t0.09948539162996513\n",
      "  (0, 35260)\t0.16631336925205778\n",
      "  (0, 18068)\t0.0703824494629968\n",
      "  (0, 43125)\t0.05694319449308712\n",
      "  (0, 16812)\t0.08573609492888531\n",
      "  :\t:\n",
      "  (14905, 44804)\t0.10944322310624707\n",
      "  (14905, 27329)\t0.1600907554717236\n",
      "  (14905, 12016)\t0.11296146190025841\n",
      "  (14905, 36428)\t0.13309169182008374\n",
      "  (14905, 24635)\t0.14378164367665197\n",
      "  (14905, 19119)\t0.10809720222452268\n",
      "  (14905, 14183)\t0.09674610153729479\n",
      "  (14905, 45065)\t0.37719124012168126\n",
      "  (14905, 32200)\t0.13418339940213397\n",
      "  (14905, 34429)\t0.11290245144805278\n",
      "  (14905, 22432)\t0.2615973543698295\n",
      "  (14905, 24704)\t0.13217449867539427\n",
      "  (14905, 44408)\t0.12339184156796283\n",
      "  (14905, 14213)\t0.11692639995267219\n",
      "  (14905, 16670)\t0.13019777497274757\n",
      "  (14905, 10002)\t0.12656109056800188\n",
      "  (14905, 43067)\t0.18567692206252734\n",
      "  (14905, 43325)\t0.18803068915760296\n",
      "  (14905, 28297)\t0.14504837582189936\n",
      "  (14905, 39172)\t0.18352810106065867\n",
      "  (14905, 39320)\t0.15674232535012977\n",
      "  (14905, 33051)\t0.1626033496059678\n",
      "  (14905, 1838)\t0.17566361150508594\n",
      "  (14905, 4873)\t0.24489501400336444\n",
      "  (14905, 4872)\t0.24489501400336444 <Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 1861538 stored elements and shape (14906, 47666)>\n",
      "  Coords\tValues\n",
      "  (0, 16958)\t0.04648173424595196\n",
      "  (0, 32711)\t0.025093080146973878\n",
      "  (0, 16318)\t0.06271063693846175\n",
      "  (0, 43439)\t0.19525670108429782\n",
      "  (0, 42275)\t0.09091413529571152\n",
      "  (0, 37397)\t0.05613408354652328\n",
      "  (0, 12239)\t0.1799541746862869\n",
      "  (0, 32625)\t0.15949553627979712\n",
      "  (0, 9644)\t0.036054055857422315\n",
      "  (0, 33908)\t0.08862481250274072\n",
      "  (0, 20429)\t0.028457896072822467\n",
      "  (0, 15589)\t0.05993707248217903\n",
      "  (0, 37402)\t0.05993707248217903\n",
      "  (0, 40306)\t0.2914770080570622\n",
      "  (0, 22579)\t0.022744342737391603\n",
      "  (0, 10717)\t0.030468573113361284\n",
      "  (0, 14181)\t0.09975404740412462\n",
      "  (0, 35280)\t0.05942443972945572\n",
      "  (0, 40475)\t0.036551496047030944\n",
      "  (0, 32473)\t0.10351691994529\n",
      "  (0, 21128)\t0.0328586893566479\n",
      "  (0, 14660)\t0.04080684779994565\n",
      "  (0, 36565)\t0.09735221361512342\n",
      "  (0, 14951)\t0.1474153168606564\n",
      "  (0, 11825)\t0.02967914544209675\n",
      "  :\t:\n",
      "  (14905, 22655)\t0.1965163855805661\n",
      "  (14905, 36872)\t0.10852290428047193\n",
      "  (14905, 24909)\t0.11723948610634173\n",
      "  (14905, 19311)\t0.08814240896311502\n",
      "  (14905, 14322)\t0.07888672668489079\n",
      "  (14905, 45589)\t0.3075615636661456\n",
      "  (14905, 32603)\t0.10941308214062911\n",
      "  (14905, 34858)\t0.09206060696929798\n",
      "  (14905, 22681)\t0.18499571369719864\n",
      "  (14905, 43823)\t0.10262129635761819\n",
      "  (14905, 3973)\t0.09089359476452785\n",
      "  (14905, 24978)\t0.10777502541225228\n",
      "  (14905, 44923)\t0.10061365084736633\n",
      "  (14905, 14352)\t0.0953417327287232\n",
      "  (14905, 11465)\t0.2623947747189597\n",
      "  (14905, 16836)\t0.10616320581451766\n",
      "  (14905, 10107)\t0.1031978550239663\n",
      "  (14905, 43563)\t0.1514008768280125\n",
      "  (14905, 28649)\t0.11827237891480878\n",
      "  (14905, 39641)\t0.1496487291716667\n",
      "  (14905, 39789)\t0.12780761998025686\n",
      "  (14905, 33462)\t0.13258669646206814\n",
      "  (14905, 1842)\t0.14323602800615787\n",
      "  (14905, 4894)\t0.1996872817529357\n",
      "  (14905, 4893)\t0.1996872817529357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect= TfidfVectorizer()\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "clf = MultiOutputClassifier(MultinomialNB()).fit(X_train_vect, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_pred = clf.predict(X_test_vect)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
