{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bibcode</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>verified_uat_ids</th>\n",
       "      <th>verified_uat_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020ApJ...891..100S</td>\n",
       "      <td>Dynamic Potential Sputtering of Lunar Analog M...</td>\n",
       "      <td>Pyroxenes ((Ca, Mg, Fe, Mn)&lt;SUB&gt;2&lt;/SUB&gt;Si&lt;SUB&gt;...</td>\n",
       "      <td>[1534, 499, 1692, 948, 1024, 2004]</td>\n",
       "      <td>[solar wind, exosphere, the moon, lunar compos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024ApJ...966L...8B</td>\n",
       "      <td>Generation of Low-inclination, Neptune-crossin...</td>\n",
       "      <td>The solar system's distant reaches exhibit a w...</td>\n",
       "      <td>[1705, 1184, 2293]</td>\n",
       "      <td>[trans-neptunian objects, orbits, solar system...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024PSJ.....5...45C</td>\n",
       "      <td>Leveraging the Gravity Field Spectrum for Icy ...</td>\n",
       "      <td>Understanding the interior structures of icy m...</td>\n",
       "      <td>[2189, 1248, 770, 1889, 627, 1255]</td>\n",
       "      <td>[europa, planetary interior, hydrosphere, mark...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022ApJ...932...52H</td>\n",
       "      <td>Inverse Multiview. I. Multicalibrator Inverse ...</td>\n",
       "      <td>Very Long Baseline Interferometry (VLBI) astro...</td>\n",
       "      <td>[1769, 1337, 1713, 1295]</td>\n",
       "      <td>[very long baseline interferometry, radio astr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024ApJS..271...25C</td>\n",
       "      <td>The First LHAASO Catalog of Gamma-Ray Sources</td>\n",
       "      <td>We present the first catalog of very-high-ener...</td>\n",
       "      <td>[628, 632, 205]</td>\n",
       "      <td>[gamma-ray astronomy, gamma-ray observatories,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               bibcode                                              title  \\\n",
       "0  2020ApJ...891..100S  Dynamic Potential Sputtering of Lunar Analog M...   \n",
       "1  2024ApJ...966L...8B  Generation of Low-inclination, Neptune-crossin...   \n",
       "2  2024PSJ.....5...45C  Leveraging the Gravity Field Spectrum for Icy ...   \n",
       "3  2022ApJ...932...52H  Inverse Multiview. I. Multicalibrator Inverse ...   \n",
       "4  2024ApJS..271...25C      The First LHAASO Catalog of Gamma-Ray Sources   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Pyroxenes ((Ca, Mg, Fe, Mn)<SUB>2</SUB>Si<SUB>...   \n",
       "1  The solar system's distant reaches exhibit a w...   \n",
       "2  Understanding the interior structures of icy m...   \n",
       "3  Very Long Baseline Interferometry (VLBI) astro...   \n",
       "4  We present the first catalog of very-high-ener...   \n",
       "\n",
       "                     verified_uat_ids  \\\n",
       "0  [1534, 499, 1692, 948, 1024, 2004]   \n",
       "1                  [1705, 1184, 2293]   \n",
       "2  [2189, 1248, 770, 1889, 627, 1255]   \n",
       "3            [1769, 1337, 1713, 1295]   \n",
       "4                     [628, 632, 205]   \n",
       "\n",
       "                                 verified_uat_labels  \n",
       "0  [solar wind, exosphere, the moon, lunar compos...  \n",
       "1  [trans-neptunian objects, orbits, solar system...  \n",
       "2  [europa, planetary interior, hydrosphere, mark...  \n",
       "3  [very long baseline interferometry, radio astr...  \n",
       "4  [gamma-ray astronomy, gamma-ray observatories,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_parquet('train-00000-of-00001-b21313e511aa601a.parquet')\n",
    "\n",
    "# Drop rows with any missing values\n",
    "data = data.dropna(ignore_index=True)\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Loading the data, we're going to prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['title'] + data['abstract']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On va créer un dictionnaire avec les valeurs des ids vérifiés, associé à chaque label vérifié et créer une liste Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_and_labels = data[['verified_uat_ids','verified_uat_labels']]\n",
    "\n",
    "maxi = 0\n",
    "for i in data['verified_uat_ids']: \n",
    "    for j in i:\n",
    "        if j>maxi:\n",
    "            maxi = j\n",
    "\n",
    "y_liste = np.zeros((len(data),maxi+1))\n",
    "\n",
    "dict_ids_labels = {}\n",
    "\n",
    "for i in range(len(ids_and_labels['verified_uat_ids'])):\n",
    "    for j in range(len(ids_and_labels['verified_uat_ids'][i])):\n",
    "        y_liste[i][ids_and_labels['verified_uat_ids'][i][j]] = 1\n",
    "        dict_ids_labels[ids_and_labels['verified_uat_ids'][i][j]] = ids_and_labels['verified_uat_labels'][i][j]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Y with columns equals to the value of the labels, with 1 if the label appears in the data for each line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame(y_liste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to separate our data into train and test datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to tokenize the text, by the frequence of each word, so our model can handle it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vect= TfidfVectorizer()\n",
    "X_train_vect = vect.fit_transform(X_train)\n",
    "X_test_vect = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = MultiOutputClassifier(MultinomialNB()).fit(X_train_vect, Y_train)\n",
    "# Tune the hyperparameters of the MultinomialNB model\n",
    "\n",
    "param_grid = {\n",
    "    'estimator__alpha': [0.1, 0.5, 1.0, 2.0, 5.0]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(MultiOutputClassifier(MultinomialNB()), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train_vect, Y_train)\n",
    "\n",
    "# Use the best estimator found by GridSearchCV\n",
    "clf = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "Y_pred = clf.predict(X_test_vect)\n",
    "accuracy = accuracy_score(Y_test, Y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
